@[toc]
## 一.项目介绍

### 1.拓扑图

![请添加图片描述](https://img-blog.csdnimg.cn/c23faf7230ef46fb8d0d4c692c891885.png)



### 2.详细介绍

项目名称：基于keepalived+mysqlrouter+gtid半同步复制的MySQL集群
项目环境：centos7.9，mysql5.7.30，mysqlrouter8.0.21，keepalived 1.3.5，ansible 2.9.27等
项目描述：
     本项目的目的是构建一个高可用的能实现读写分离的高效的MySQL集群，确保业务的稳定，能沟通方便的监控整个集群，同时能批量的去部署和管理整个集群。

项目步骤：
	1.配置好ansible服务器并建立免密通道，一键安装MySQL、mysqlroute、node_exporters、dns等软件，在master上导出基础数据到ansible上，发布到所有slave服务器上并导入
	2.安装好半同步相关的插件，开启gtid功能，启动主从复制服务，配置延迟备份服务器，从slave1上拿二进制日志
	3.在master上创建一个计划任务每天2:30进行数据库的备份脚本，使用rsync+sersync远程同步到slave4异地备份服务器上
	4.安装部署mysqlrouter中间件软件，实现读写分离；安装keepalived实现高可用，配置2个vrrp实例实现双vip的高可用功能
	5.搭建DNS域名服务器，配置一个域名对应2个vip，实现基于DNS的负载均衡，访问同一URL解析出双vip地址
	6.使用sysbench整个MySQL集群的性能（cpu、IO、内存等）进行压力测试，安装部署prometheus实现监控，grafana出图了解系统性能的瓶颈并调优

项目心得：
1.一定要规划好整个集群的架构，配置要细心，脚本要提前准备好，边做边修改，防火墙和selinux的问题一定要多注意
2.对MySQL的集群和高可用有了深入的理解，对自动化批量部署和监控有了更加多的应用和理解
3.keepalived的配置需要更加细心，对keepalievd的脑裂和vip漂移现象也有了更加深刻的体会和分析
4.认识到了系统性能资源的重要性，对压力测试下整个集群的瓶颈有了一个整体概念

## 二.前期准备

### 1.项目环境

centos7.9，mysql5.7.30，mysqlrouter8.0.21，keepalived 1.3.5，ansible 2.9.27等

### 2.IP划分

准备11台centos7.9的虚拟机，并且分配IP地址：

|       主机名       |       IP       |
| :----------------: | :------------: |
|     DNS服务器      | 192.168.98.144 |
|    mysqlrouter1    | 192.168.98.143 |
|    mysqlrouter2    | 192.168.98.138 |
|       master       | 192.168.98.131 |
|       slave1       | 192.168.98.142 |
|       slave2       | 192.168.98.140 |
|       slave3       | 192.168.98.135 |
|       slave4       | 192.168.98.146 |
|      ansible       | 192.168.98.147 |
|     监控服务器     | 192.168.98.145 |
| sysbench压力测试机 | 192.168.98.148 |

## 三. 项目步骤

### 1.ansible部署软件环境

> 配置好ansible服务器并建立免密通道，一键安装MySQL、mysqlroute、node_exporters、dns等软件，在master上导出基础数据到ansible上，发布到所有slave服务器上并导入

#### 1.1 安装ansible环境

```shell
[root@ansible ~]# yum install epel-release -y
[root@ansible ~]# yum install ansible -y
```

```shell
#修改配置文件，只需要配置如下八台，监控和压力测试机单独部署
[root@localhost ~]# vim /etc/ansible/hosts
[mysqlrouter]
192.168.98.143
192.168.98.138

[mysql]
192.168.98.131
192.168.98.142
192.168.98.140
192.168.98.135
192.168.98.146

[dns]
192.168.98.144
```

#### 1.2 建立免密通道

```shell
[root@localhost ~]# ssh-keygen -t rsa
[root@localhost ~]# cd .ssh
[root@localhost .ssh]# ls
id_rsa  id_rsa.pub  known_hosts
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.144
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.143
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.138
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.142
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.140
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.135
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.131
[root@localhost .ssh]# ssh-copy-id -i id_rsa.pub root@192.168.98.146
```

#### 1.3 ansible批量部署软件

1.3.1 在ansible机器上面创建nginx脚本

```shell
[root@localhost ~]#vim onekey_install_mysql.sh
```

```shell
#!/bin/bash

#解决软件的依赖关系
yum  install cmake ncurses-devel gcc  gcc-c++  vim  lsof bzip2 openssl-devel ncurses-compat-libs net-tools -y

#下载安装包到家目录下(由于文件较大请自行下载)
cd ~
#curl -O https://dev.mysql.com/downloads/file/?id=519542

#解压mysql二进制安装包
tar  xf  mysql-5.7.43-linux-glibc2.12-x86_64.tar.gz

#移动mysql解压后的文件到/usr/local下改名叫mysql
mv mysql-5.7.43-linux-glibc2.12-x86_64 /usr/local/mysql

#新建组和用户 mysql
groupadd mysql
#mysql这个用户的shell 是/bin/false 属于mysql组 
useradd -r -g mysql -s /bin/false mysql

#关闭firewalld防火墙服务，并且设置开机不要启动
service firewalld stop
systemctl  disable  firewalld

#临时关闭selinux
setenforce 0
#永久关闭selinux
sed -i '/^SELINUX=/ s/enforcing/disabled/'  /etc/selinux/config

#新建存放数据的目录
mkdir  /data/mysql -p
#修改/data/mysql目录的权限归mysql用户和mysql组所有，这样mysql用户可以对这个文件夹进行读写了
chown mysql:mysql /data/mysql/
#只是允许mysql这个用户和mysql组可以访问，其他人都不能访问
chmod 750 /data/mysql/

#进入/usr/local/mysql/bin目录
cd /usr/local/mysql/bin/

#初始化mysql
./mysqld  --initialize --user=mysql --basedir=/usr/local/mysql/  --datadir=/data/mysql  &>passwd.txt

#让mysql支持ssl方式登录的设置
./mysql_ssl_rsa_setup --datadir=/data/mysql/

#获得临时密码
tem_passwd=$(cat passwd.txt |grep "temporary"|awk '{print $NF}')
  #$NF表示最后一个字段
  # abc=$(命令)  优先执行命令，然后将结果赋值给abc 

# 修改PATH变量，加入mysql bin目录的路径
#临时修改PATH变量的值
export PATH=/usr/local/mysql/bin/:$PATH
#重新启动linux系统后也生效，永久修改
echo  "PATH=/usr/local/mysql/bin:$PATH">>/root/.bashrc

#复制support-files里的mysql.server文件到/etc/init.d/目录下叫mysqld
cp  ../support-files/mysql.server   /etc/init.d/mysqld

#修改/etc/init.d/mysqld脚本文件里的datadir目录的值
sed  -i '70c  datadir=/data/mysql'  /etc/init.d/mysqld

#生成/etc/my.cnf配置文件
cat  >/etc/my.cnf  <<EOF
[mysqld_safe]

[client]
socket=/data/mysql/mysql.sock

[mysqld]
socket=/data/mysql/mysql.sock
port = 3306
open_files_limit = 8192
innodb_buffer_pool_size = 512M
character-set-server=utf8

[mysql]
auto-rehash
prompt=\\u@\\d \\R:\\m  mysql>
EOF

#修改内核的open file的数量
ulimit -n 1000000
#设置开机启动的时候也配置生效
echo "ulimit -n 1000000" >>/etc/rc.local
chmod +x /etc/rc.d/rc.local

#启动mysqld进程
service mysqld start

#将mysqld添加到linux系统里服务管理名单里
/sbin/chkconfig --add mysqld
#设置mysqld服务开机启动
/sbin/chkconfig mysqld on

#初次修改密码需要使用--connect-expired-password 选项
#-e 后面接的表示是在mysql里需要执行命令  execute 执行
#set password='123456';  修改root用户的密码为123456
mysql -uroot -p$tem_passwd --connect-expired-password   -e  "set password='123456';"

#检验上一步修改密码是否成功，如果有输出能看到mysql里的数据库，说明成功。
mysql -uroot -p'123456'  -e "show databases;"
```

1.3.2 在ansible机器上面创建node_exporter脚本，为prometheus在node节点服务器上（mysql和mysqlrouter）采集数据

```shell
[root@ansible ~]# vim node_exporter.sh
```

```shell
#!/bin/bash

#进入root家目录
cd ~
#下载node_exporter源码(由于github无法访问，故省略该步，手动下载)
#curl -O https://github.com/prometheus/node_exporter/releases/download/v1.6.1/node_exporter-1.6.1.linux-amd64.tar.gz
#解压node_exporters源码包
tar xf node_exporter-1.6.1.linux-amd64.tar.gz
#改名
mv  node_exporter-1.6.1.linux-amd64 /node_exporter
cd /node_exporter
#修改PATH环境变量
PATH=/node_exporter:$PATH 
echo "PATH=/node_exporter:$PATH" >>/root/.bashrc
#后台运行，监听8090端口
nohup node_exporter --web.listen-address 0.0.0.0:8090  &
```

1.3.3 在ansible机器上面编写playbook批量部署mysql、mysqlroute、node_exporters、dns等软件

```shell
[root@ansible ~]# vim software_install.yaml
```

```shell
- hosts: mysql #mysql集群
  remote_user: root
  tasks:  
  - name: copy mysql.tar.gz     #上传MySQL安装包到mysql主机组
    copy: src=/root/mysql-5.7.43-linux-glibc2.12-x86_64.tar.gz dest=/root/
  - name: copy mysql.sh     #上传脚本到mysql主机组
    copy: src=/root/onekey_install_mysql.sh dest=/root/
  - name: install mysql #安装MySQL
    script: /root/onekey_install_mysql.sh

- hosts: mysqlrouter #mysqlrouter服务器
  remote_user: root
  tasks:
  - name: copy file     #上传mysqlrouter安装包到服务器
    copy: src=/root/mysql-router-community-8.0.23-1.el7.x86_64.rpm dest=/root/
  - name: install mysqlrouter #安装mysqlrouter
    shell:  rpm -ivh mysql-router-community-8.0.23-1.el7.x86_64.rpm
  - name: install keepalived  #安装keepalived实现高可用
    yum: name=keepalived state=installed

- hosts: dns #dns服务器
  remote_user: root
  tasks:
  - name: install dns
    yum: name=bind.* state=installed


- hosts: mysqlrouter mysql #调用本地node_exporter脚本，批量安装部署node_exporter，为prometheus采集数据
  remote_user: root
  tasks:
  - name: copy file     #上传node_exporter安装包到服务器
    copy: src=/root/node_exporter-1.6.1.linux-amd64.tar.gz dest=/root/
  - name: copy file     #上传脚本到服务器
    copy: src=/root/node_exporter.sh dest=/root/
  - name: install node_exporters  #执行脚本
    script: /root/node_exporter.sh
    tags: install_exporter
  - name: start node_exporters  #后台运行node_exporters
    shell: nohup node_exporter --web.listen-address 0.0.0.0:8090 &
    tags: start_exporters  #打标签，方便后面直接跳转到此处批量启动node_exporters
```

```shell
[root@localhost ~]# ansible-playbook software_install.yaml
```

#### 1.4 统一5台mysql服务器的数据

> master服务器上面导出数据

```shell
[root@localhost ~]# mysqldump -uroot -p'123456'  --all-databases  >all_db.SQL
```

> 使用ansible导入到其他机器

```shell
#拷贝master上的MySQL数据包到ansible机器上
[root@localhost ~]#scp  root@192.168.98.131:/root/all_db.SQL   /root
#下发到mysql数据库服务器上面
[root@localhost ~]# ansible mysql -m copy -a "src=/root/all_db.SQL dest=/root/"
[root@localhost ~]# ansible mysql -m shell -a "mysql -uroot -p'123456' <all_db.SQL"
```

### 2.配置基于GTID的半同步主从复制

> 安装好半同步相关的插件，开启gtid功能，启动主从复制服务，配置延迟备份服务器，从slave1上拿二进制日志

#### 2.1 在master上安装配置半同步的插件,再配置

2.1.1 在master上安装配置半同步的插件，配置半同步复制超时时间，修改配置文件/etc/my.cnf

```shell
[root@localhost ~]# mysql -uroot -p'123456'
root@(none) 11:08  mysql>install plugin rpl_semi_sync_master SONAME 'semisync_master.so';

root@(none) 11:08  mysql>exit
```

```shell
[root@localhost ~]# vim /etc/my.cnf
[mysqld]
#二进制日志开启
log_bin
server_id = 1
 
#开启半同步，需要提前安装半同步的插件
rpl_semi_sync_master_enabled=1
rpl_semi_sync_master_timeout=1000 # 1 second
#gtid功能
gtid-mode=ON
enforce-gtid-consistency=ON

[root@sc-master mysql]# service mysqld restart
```

2.1.2 在每台从服务器上配置安装半同步的插件，配置slave配置文件

```shell
[root@localhost ~]# mysql -uroot -p'123456'
root@(none) 11:12  mysql>install plugin rpl_semi_sync_slave SONAME 'semisync_slave.so';
root@(none) 11:12  mysql>set global rpl_semi_sync_slave_enabled = 1;
root@(none) 11:13  mysql>exit
```

```shell
[root@localhost ~]# vim /etc/my.cnf
[mysqld]
#log bin 二进制日志
log_bin
server_id = 2 #注意：每台slave的id都不一样
expire_logs_days = 15 #二进制日志保存15天

#开启半同步，需要提前安装半同步的插件
rpl_semi_sync_slave_enabled=1
#开启gtid功能
gtid-mode=ON
enforce-gtid-consistency=ON
log_slave_updates=ON

[root@sc-slave mysql]#  service mysqld restart
```

2.1.3 在master上新建一个授权用户，给slave1和salve2来复制二进制日志

```shell
root@(none) 12:06  mysql>grant replication slave on *.* to 'master'@'192.168.98.%' identified by '123456';
```

> 在slave1上创建授权用户，给salve3复制二进制日志

```shell
root@(none) 12:06  mysql>grant replication slave on *.* to 'slave1'@'192.168.98.%' identified by '123456';
```

2.1.4 在slave上配置master info的信息

> 在salve1和slave2上配置

```shell
#停止
root@(none) 12:06  mysql>stop slave;
#清空
root@(none) 12:07  mysql>reset slave all;
#配置
root@(none) 12:07  mysql>
change master to master_host='192.168.98.131' ,
master_user='master',
master_password='123456',
master_port=3306,
master_auto_position=1;
#开启
root@(none) 16:33  scmysql>start slave;
```

> 在slave3上配置

```shell
#停止
root@(none) 12:06  mysql>stop slave;
#清空
root@(none) 12:07  mysql>reset slave all;
#配置
root@(none) 12:07  mysql>
change master to master_host='192.168.98.142' ,
master_user='slave1',
master_password='123456',
master_port=3306,
master_auto_position=1;
#开启
root@(none) 16:33  scmysql>start slave;
```

2.1.5 查看

```shell
在slave上查看
root@(none) 16:34  scmysql>show slave status\G;

在master上查看
root@(none) 16:35  mysql>show variables like "%semi_sync%";

在slave上查看
root@(none) 16:35  scmysql>show variables like "%semi_sync%";
```

2.1.6 验证GTID的半同步主从复制

> 在master上面新建或者删除库，slave上面查看有没有实现

#### 2.2配置slave3延迟备份服务器

> 在slave3上面操作

```shell
#停止同步服务
root@(none) 13:42  mysql>stop slave;
#延迟10分钟再备份
root@(none) 13:42  mysql>change master to master_delay = 600;
#开始同步
root@(none) 13:43  mysql>start slave;
#查看设置情况
root@(none) 13:43  mysql>show slave status\G;
SQL_Delay: 60
```

### 3.master创建一个计划任务，远程同步到slave4异地备份服务器

> 在master上创建一个计划任务每天2:30进行数据库的备份脚本，使用rsync+sersync远程同步到slave4异地备份服务器上

#### 3.1 在slave4远程备份服务器上操作

3.1.1 slave4远程备份服务器一键安装rsync服务端软件并且设置开机启动

```shell
[root@localhost ~]# vim onekey_install_rsync.sh
```

```shell
#!/bin/bash

#创建备份目录
mkdir  /backup

#关闭firewalld防火墙服务，并且设置开机不要启动
service firewalld stop
systemctl  disable  firewalld
#临时关闭selinux
setenforce 0
#永久关闭selinux
sed -i '/^SELINUX=/ s/enforcing/disabled/'  /etc/selinux/config

#安装rsync服务端软件
yum install rsync xinetd -y

#设置开机启动
echo '/usr/bin/rsync --daemon --config=/etc/rsyncd.conf' >>/etc/rc.d/rc.local
chmod +x /etc/rc.d/rc.local

#生成/etc/rsyncd.conf配置文件
cat  >/etc/rsyncd.conf  <<EOF
uid = root
gid = root
use chroot = yes
max connections = 0
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsync.lock
secrets file = /etc/rsync.pass
motd file = /etc/rsyncd.Motd

[back_data]
     path = /backup
     comment = A directory in which data is stored
     ignore errors = yes
     read only = no
     hosts allow = 192.168.98.131
EOF

#创建用户认证文件
cat  >/etc/rsync.pass  <<EOF
slave:123456
EOF

#设置文件所有者读取、写入权限
chmod 600 /etc/rsyncd.conf  
chmod 600 /etc/rsync.pass

#启动rsync
/usr/bin/rsync --daemon --config=/etc/rsyncd.conf
#启动xinetd(xinetd是一个提供保姆服务的进程，rsync是它照顾的进程)
systemctl start xinetd
```

> xinetd是一个提供保姆服务的进程，rsync是它照顾的进程

3.1.2 查看rsync和xinetd监听的进程

```shell
[root@sc-mysql2 backup]# ps aux|grep rsync
root      9455  0.0  0.0 114844   584 ?        Ss   16:13   0:00 /usr/bin/rsync --daemon --config=/etc/rsyncd.conf
root      9457  0.0  0.0 112824   988 pts/0    S+   16:13   0:00 grep --color=auto rsync
[root@sc-mysql2 backup]# ps aux|grep xinetd
root      9425  0.0  0.0  25044   584 ?        Ss   16:00   0:00 /usr/sbin/xinetd -stayalive -pidfile /var/run/xinetd.pid
root      9465  0.0  0.0 112824   988 pts/0    S+   16:14   0:00 grep --color=auto xinetd
```

#### 3.2 数据源master服务器操作

3.2.1 master服务器一键安装rsync服务端软件并且设置开机启动

```shell
[root@localhost ~]# vim onekey_install_rsync.sh
```

```shell
#!/bin/bash

#关闭firewalld防火墙服务，并且设置开机不要启动
service firewalld stop
systemctl  disable  firewalld
#临时关闭selinux
setenforce 0
#永久关闭selinux
sed -i '/^SELINUX=/ s/enforcing/disabled/'  /etc/selinux/config

#安装rsync服务端软件
yum install rsync xinetd -y

#设置开机启动
echo '/usr/bin/rsync --daemon --config=/etc/rsyncd.conf' >>/etc/rc.d/rc.local
chmod +x /etc/rc.d/rc.local

#生成/etc/rsyncd.conf配置文件
cat  >/etc/rsyncd.conf  <<EOF
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsync.lock
motd file = /etc/rsyncd.Motd
[Sync]
    comment = Sync
    uid = root
    gid = root
    port= 873
EOF

#启动xinetd(xinetd是一个提供保姆服务的进程，rsync是它照顾的进程)
systemctl start xinetd

#创建认证密码文件，该密码应与slave服务器中的/etc/rsync.pass中的密码一致 
cat  >/etc/passwd.txt  <<EOF
123456
EOF

#设置文件所有者读取、写入权限
chmod 600 /etc/passwd.txt 
```

3.2.2 测试数据源master服务器192.168.98.131 到slave异地备份服务器192.168.98.146之间的数据同步

> /backup(要备份的数据源目录,自己创建)   root@192.168.98.146::back_data(rsyncd.conf文件配置名称)

```shell
[root@sc-mysql backup]# rsync -avH --port=873 --progress --delete  /backup  root@192.168.98.146::back_data --password-file=/etc/passwd.txt
```

3.2.3 数据源服务器上安装sersync工具，实现自动的实时的同步

（1）一键安装安装sersync工具

```
[root@localhost ~]# vim onekey_install_sersync.sh
```

```shell
#!/bin/bash
cd ~
#修改inotify默认参数（inotify默认内核参数值太小）
sysctl -w fs.inotify.max_queued_events="99999999"
sysctl -w fs.inotify.max_user_watches="99999999"
sysctl -w fs.inotify.max_user_instances="65535"

#下载并安装sersync
yum install wget -y
wget http://down.whsir.com/downloads/sersync2.5.4_64bit_binary_stable_final.tar.gz

#解压并改名
tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz
mv /root/GNU-Linux-x86 /usr/local/sersync

#创建rsync
cd /usr/local/sersync/
cp confxml.xml confxml.xml.bak
cp confxml.xml data_configxml.xml   #data_configxml.xml 是后面需要使用的配置文件

#修改data_configxml.xml配置文件
#修改需要备份的路径为/backup
sed -i 's/watch="\/opt\/tongbu"/watch="\/backup"/' /usr/local/sersync/data_configxml.xml
#修改服务器信息为slave4远程备份服务器
sed -i 's/ip="127.0.0.1" name="tongbu1"/ip="192.168.98.146" name="back_data"/' /usr/local/sersync/data_configxml.xml
#开启身份认证，修改密码文件为/etc/passwd.txt
sed -i 's/start="false" users="root" passwordfile="\/etc\/rsync.pas"/start="true" users="root" passwordfile="\/etc\/passwd.txt"/' /usr/local/sersync/data_configxml.xml


#添加到PATH变量
PATH=/usr/local/sersync/:$PATH
echo 'PATH=/usr/local/sersync/:$PATH'  >>/root/.bashrc

#启动
sersync2 -d -r -o  /usr/local/sersync/data_configxml.xml

#设计开机启动
echo '/usr/local/sersync/sersync2 -d -r -o  /usr/local/sersync/data_configxml.xml' >>/etc/rc.local 
```

- 永久修改参数方法

  ```shell
  [root@sc-mysql backup]# vim /etc/sysctl.conf
  fs.inotify.max_queued_events=99999999
  fs.inotify.max_user_watches=99999999
  fs.inotify.max_user_instances=65535
  ```

![在这里插入图片描述](https://img-blog.csdnimg.cn/3dbefe28835b4b7dbf1ccd48aa7030d5.png#pic_center)


（2）查看服务，新建文件进行验证

```shell
[root@sc-mysql backup]# ps aux|grep sersync
[root@master backup]# mkdir test
[root@master backup]# ls
test
[root@slave4 backup]# ls
test
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/44e8e79fcec742519b9b6c82b5702b77.png#pic_center)


#### 3.3 创建计划任务

> 在master上创建一个计划任务每天2:30进行数据库的备份脚本

```shell
[root@localhost ~]#crontab -e
30 2 * * * bash /root/backup_log.sh
```

```shell
[root@localhost ~]# vim /root/backup_log.sh
mysqldump -uroot -p'123456'  --all-databases  >/backup/all_db.SQL
```

### 4 部署mysqlrouter中间件实现读写分离，安装keepalived部署双vip实现高可用

#### 4.1  部署mysqlrouter中间件实现读写分离

4.1.1 安装部署MySQLrouter（该步骤已经使用playbook部署完成）

- 上传或者去官方网站下载软件

> https://dev.mysql.com/get/Downloads/MySQL-Router/mysql-router-community-8.0.23-1.el7.x86_64.rpm

```shell
[root@mysql-router-1 ~]# rpm -ivh mysql-router-community-8.0.23-1.el7.x86_64.rpm 
```

4.1.2 修改配置文件/etc/mysqlrouter/mysqlrouter.conf

```shell
[root@mysql-router-1 mysqlrouter]# vim /etc/mysqlrouter/mysqlrouter.conf

[DEFAULT]
logging_folder = /var/log/mysqlrouter
runtime_folder = /var/run/mysqlrouter
config_folder = /etc/mysqlrouter

[logger]
level = INFO

[keepalive]
interval = 60

[routing:slave]
bind_address = 0.0.0.0:7001
destinations = 192.168.98.131:3306,192.168.98.142:3306
mode = read-only
connect_timeout = 1

[routing:master]
bind_address = 0.0.0.0:7002
destinations = 192.168.98.131:3306
mode = read-write
connect_timeout = 1
```

4.1.3 启动MySQL router服务,监听了7001和7002端口

```shell
[root@localhost ~]# service mysqlrouter restart
[root@localhost ~]# netstat -anplut|grep mysql
tcp        0      0 0.0.0.0:7001            0.0.0.0:*               LISTEN      8084/mysqlrouter    
tcp        0      0 0.0.0.0:7002            0.0.0.0:*               LISTEN      8084/mysqlrouter  
```

4.1.4 在master上创建2个测试账号，一个是读的，一个是写的()

```shell
root@(none) 15:34  mysql>grant all on *.*  to 'write'@'%' identified by '123456';
root@(none) 15:35  mysql>grant select on *.*  to 'read'@'%' identified by '123456';
```

> 由于实现了半同步复制，故需要将slave机器上面的write用户删除

```shell
[root@localhost ~]# mysql -uroot -p'123456'
root@(none) 22:05  mysql>drop user 'write'@'%';
```

4.1.5 在客户端上测试读写分离的效果，使用2个测试账号

```shell
#实现读功能
[root@node1 ~]# mysql -h 192.168.98.143 -P 7001 -uread -p'123456'
#实现写功能
[root@node1 ~]# mysql -h 192.168.98.138 -P 7002 -uwrite -p'123456'
```

> mysqlrouter通过7001和7002端口实现分流，再通过mysql服务器上面的权限用户（write，read）进行读写分离

#### 4.2安装keepalived部署双vip实现高可用

> 

> mysqlrouter1上配置

```shell
[root@localhost conf]# vim /etc/keepalived/keepalived.conf
```

```shell
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id LVS_DEVEL
   vrrp_skip_check_adv_addr
   #vrrp_strict
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}
vrrp_instance VI_1 {
    state MASTER
    interface ens33
    virtual_router_id 88
    priority 120
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.98.88
    }
}
vrrp_instance VI_2 {
    state BACKUP
    interface ens33
    virtual_router_id 99
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.98.99
    }
}
```

```shell
[root@localhost conf]# service keepalived restart
```

> mysqlrouter2上配置

```shell
[root@localhost conf]# vim /etc/keepalived/keepalived.conf
```

```shell
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id LVS_DEVEL
   vrrp_skip_check_adv_addr
   vrrp_strict
   vrrp_garp_interval 0
   vrrp_gna_interval 0
}

vrrp_instance VI_1 {
    state MASTER
    interface ens33
    virtual_router_id 88
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.98.88
    }
}
vrrp_instance VI_2 {
    state BACKUP
    interface ens33
    virtual_router_id 99
    priority 120
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.98.99
    }
}
```

```shell
[root@localhost conf]# service keepalived restart
```

![](https://img-blog.csdnimg.cn/img_convert/0dfd1bb602d0cc1a926347a35c18454d.png)

> 在客户端上使用虚拟ip进行测试读写分离的效果

```shell
#实现读功能
[root@node1 ~]# mysql -h 192.168.98.88 -P 7001 -uread -p'123456'
#实现写功能
[root@node1 ~]# mysql -h 192.168.98.99 -P 7002 -uwrite -p'123456'
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/107f24dbc7864d60b651aae0bedf02b0.png#pic_center)


### 5.搭建DNS域名服务器

> 搭建DNS域名服务器，配置一个域名对应2个vip，实现基于DNS的负载均衡，访问同一URL解析出双vip地址

1.安装软件bind（该软件提供了很多的dns域名查询的命令）->由于playbook已经批量安装过，该处故省略

```
[root@localhost ~]# yum install bind* -y
```

2.关闭DNS域名服务器的防火墙服务和selinux

```shell
[root@localhost ~]# service firewalld stop
[root@localhost ~]#systemctl disable firewalld
#临时修改selinux策略
[root@localhost ~]# setenforce 0  
```

3.设置named服务开机启动，并且立马启动DNS服务

```shell
#设置named服务开机启动
[root@nameserver ~]# systemctl enable named  
#立马启动named进程
[root@nameserver ~]# systemctl start named  
```

4.修改dns配置文件，任意ip可以访问本机的53端口，并且允许dns解析

```shell
[root@localhost ~]# vim /etc/named.conf
options {
        listen-on port 53 { any; };  #修改
        listen-on-v6 port 53 { any; }; #修改
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        recursing-file  "/var/named/data/named.recursing";
        secroots-file   "/var/named/data/named.secroots";
        allow-query     { any; }; #修改
#重启named服务
[root@nameserver ~]# service named restart
```

5.编辑dns次要配置文件/etc/named.rfc1912.zones，增加一条主域名记录

```shell
[root@localhost ~]# vim /etc/named.rfc1912.zones
zone "liaoobo.com" IN {
        type master; #类型为主域名
        file "liaoobo.com.zone"; #liaoobo.com域名的数据文件，需要去/var/named/下创建
        allow-update { none; };
};
```

```shell
[root@localhost ~]# cd /var/named/
[root@localhost named]# cp -a named.localhost liaoobo.com.zone
[root@localhost named]# vim liaoobo.com.zone 
$TTL 1D
@       IN SOA  @ rname.invalid. (
                                        0       ; serial
                                        1D      ; refresh
                                        1H      ; retry
                                        1W      ; expire
                                        3H )    ; minimum
        NS      @
        A       127.0.0.1
        AAAA    ::1
www IN  A       192.168.98.88
www IN  A       192.168.98.99
```

![](https://img-blog.csdnimg.cn/img_convert/f177299198a52b162e397139b4cbc29b.png)

### 6.使用sysbench进行压力测试，prometheus和grafana实现监控并出图

> 使用sysbench整个MySQL集群的性能（cpu、IO、内存等）进行压力测试，安装部署prometheus实现监控，grafana出图了解系统性能的瓶颈并调优

#### 4.1 安装prometheus server

1.一键源码安装prometheus

> 源码下载：https://github.com/prometheus/prometheus/releases/download/v2.46.0/prometheus-2.46.0.linux-amd64.tar.gz

```shell
[root@localhost ~]# vim onekey_install_prometheus.sh
```

```shell
#!/bin/bash

#创建存放prometheus的目录
mkdir /prom

#下载prometheus源码(由于github无法访问，故省略该步，手动下载)
#curl -O https://github.com/prometheus/prometheus/releases/download/v2.47.0/prometheus-2.47.0.linux-amd64.tar.gz

#解压并改名
tar xf ./prometheus-2.47.0.linux-amd64.tar.gz -C /prom
mv /prom/prometheus-2.47.0.linux-amd64 /prom/prometheus

#添加到PATH变量
PATH=/prom/prometheus:$PATH
echo "PATH=/prom/prometheus:$PATH " >>/root/.bashrc

#nohub后台执行启动
nohup prometheus  --config.file=/prom/prometheus/prometheus.yml &

#关闭防火墙
service firewalld stop
systemctl disable firewalld 
```

2.把prometheus做成一个服务来进行管理

```shell
[root@prometheus prometheus]# vim /usr/lib/systemd/system/prometheus.service
[Unit]
Description=prometheus

[Service]
ExecStart=/prom/prometheus/prometheus --config.file=/prom/prometheus/prometheus.yml
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure

[Install]
WantedBy=multi-user.target

#重新加载systemd相关的服务
[root@prometheus prometheus]# systemctl daemon-reload
```

> 第一次因为是使用nohup 方式启动的prometheus，还是需要使用后kill 的方式杀死第一次启动的进程；后面可以使用service方式管理prometheus了

```shell
[root@prometheus prometheus]# ps aux|grep prometheus
root       8431  0.2  3.2 782340 61472 pts/0    Sl   11:21   0:01 prometheus --config.file=/prom/prometheus/prometheus.yml
root       8650  0.0  0.0 112824   980 pts/0    S+   11:35   0:00 grep --color=auto prome
[root@prometheus prometheus]# kill -9 8431
[root@prometheus prometheus]#  service prometheus start
[root@prometheus prometheus]#  service prometheus stop
```

3 在node节点服务器上安装exporter程序->已经使用playbook安装完成

#### 4.2 在prometheus server里添加安装了exporter程序的机器

```shell
[root@sc-prom prometheus]# vim /prom/prometheus/prometheus.yml

scrape_configs:

The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.

  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
  #添加下面的配置采集node-liangrui服务器的metrics
  - job_name: "master"
    static_configs:
      - targets: ["192.168.98.131:8090"]  
      
  - job_name: "slave1"
    static_configs:
      - targets: ["192.168.98.142:8090"]  

  - job_name: "slave2"
    static_configs:
      - targets: ["192.168.98.140:8090"]

  - job_name: "slave3"
    static_configs:
      - targets: ["192.168.98.135:8090"]

  - job_name: "slave4"
    static_configs:
      - targets: ["192.168.98.146:8090"]

  - job_name: "mysqlrouter1"
    static_configs:
      - targets: ["192.168.98.143:8090"]
  - job_name: "mysqlrouter2"
    static_configs:
      - targets: ["192.168.98.138:8090"]


#重启prometheus服务  
[root@prometheus prometheus]# service  prometheus restart
```

![](https://img-blog.csdnimg.cn/img_convert/9fc1b9bb36758600436d241d8350f217.png)

#### 4.3 grafana部署和安装

4.3.1 先去官方网站下载

```shell
wget https://dl.grafana.com/enterprise/release/grafana-enterprise-10.1.1-1.x86_64.rpm
```

4.3.2 安装

```shell
[root@sc-prom grafana]# ls
grafana-enterprise-8.4.5-1.x86_64.rpm
[root@sc-prom grafana]# yum install grafana-enterprise-10.1.1-1.x86_64.rpm -y
```

4.3.3 启动grafana

```shell
[root@sc-prom grafana]# service grafana-server start
设置grafana开机启动
[root@prometheus grafana]# systemctl enable grafana-server  
监听的端口号是3000
```

4.3.4 登录，在浏览器里登录

> http://192.168.98.147:3000/
> 默认的用户名和密码是
> 用户名admin
> 密码admin

![](https://img-blog.csdnimg.cn/img_convert/87d4c07657085cb3d5a87acae3e3cd70.png)

#### 4.4 sysbench压力测试

> ab测试机对web集群和负载均衡器进行压力测试，了解系统性能的瓶颈，对系统性能资源(如内核参数、nginx参数 )进行调优，提升系统性能

1.在压力测试机器上面设置

```shell
[root@localhost ~]# vim /etc/resolv.conf 
# Generated by NetworkManager
search localdomain
nameserver 192.168.98.144  #DNS服务器ip地址
```

2.使用yum安装,使用epel-release源去安装sysbench

```shell
[root@nfs-server ~]# yum install epel-release -y
[root@nfs-server ~]# yum install sysbench -y
```

3.在master数据库里新建sbtest的库和建10个sbtest表

```shell
[root@localhost ~]# mysql -h www.liaoobo.com -P 7002 -uwrite -p'123456'
write@(none) 12:14  mysql>create database sbtest;
[root@localhost ~]# sysbench --mysql-host=www.liaoobo.com --mysql-port=7002 --mysql-user=write --mysql-password='123456' /usr/share/sysbench/oltp_common.lua --tables=10  --table_size=10000 prepare
```

4.压力测试

```shell
[root@localhost sysbench]# sysbench --threads=4 --time=20 --report-interval=5  --mysql-host=www.liaoobo.com  --mysql-port=7002 --mysql-user=write  --mysql-password='123456' /usr/share/sysbench/oltp_read_write.lua  --tables=10  --table_size=100000  run
```

- mysql性能测试工具——tpcc

  1.下载安装包并解压，然后打开目录进行make

  ```shell
  wget  http://imysql.com/wp-content/uploads/2014/09/tpcc-mysql-src.tgz
  tar xf tpcc-mysql-src.tar
  cd tpcc-mysql/src
  make
  ```

  之后会生成两个二进制工具tpcc_load（提供初始化数据的功能）和tpcc_start(进行压力测试)

  ```shell
  [root@nfs-server src]# cd ..
  [root@nfs-server tpcc-mysql]# ls
  add_fkey_idx.sql  drop_cons.sql  schema2  tpcc_load
  count.sql         load.sh        scripts  tpcc_start
  create_table.sql  README         src
  [root@nfs-server tpcc-mysql]# 
  ```

  3、初始化数据库

  在master服务器上连接到读写分离器上创建tpcc库，需要在测试的服务器上创建tpcc的库

  ```shell
  [root@sc-slave ~]# mysqladmin -uwrite -p'123456' -h www.liaoobo.com -P 7002 create  tpcc
  ```

  需要将tpcc的create_table.sql 和add_fkey_idx.sql 远程拷贝到master服务器上

  ```shell
  [root@nfs-server tpcc-mysql]# scp create_table.sql add_fkey_idx.sql root@192.168.98.131:/root
  ```

  然后在master服务器上导入create_table.sql 和add_fkey_idx.sql 文件

  ```shell
  mysql -uroot -p'123456' tpcc <create_table.sql
  mysql -uroot -p'123456' tpcc <add_fkey_idx.sql
  ```

  4、加载数据

  > 注意：server是要测试的服务器，db，user，password也是要测的服务器上mysql的信息
  > ./tpcc_load [server] [db] [user] [password] [warehouse]
  >             服务器名 数据库名 用户名   密码      仓库数量
  > 真实测试中，数据库仓库一般不少于100个，如果配置了ssd，建议最少不低于1000个

  ```shell
  [root@nfs-server tpcc-mysql]# ./tpcc_load www.liaoobo.com:7002 tpcc write Sanchuang1234# 150
  ```

  5、进行测试

  ```shell
  ./tpcc_start -h www.liaoobo.com -p 7002 -d tpcc -u write -p 123456 -w 150 -c 12 -r 300 -l 360 -f test0.log -t test1.log - >test0.out
  ```

  > 注意：server等信息与步骤4中保持一致

## 四. 项目总结

### 1.做项目时遇到的问题

> 1.脚本执行出错，原因是github无法访问导致脚本执行失败
> 2.playbook部署mysql服务器时出错，原因是虚拟机内存不够
> 3.半同步复制部署不成功，原因是salve服务器上的server_id不能相同
> 4.keepalived的虚拟ip无法访问时，记得清除防火墙规则
> 5.DNS配置域名的数据文件和rsync的.conf配置文件出差，原因是不能加注释

### 2.项目心得

> 1.一定要规划好整个集群的架构，配置要细心，脚本要提前准备好，边做边修改
> 2.防火墙和selinux的问题一定要多注意
> 3.对MySQL的集群和高可用有了深入的理解，对自动化批量部署和监控有了更加多的应用和理解
> 4.keepalived的配置需要更加细心，对keepalievd的脑裂和vip漂移现象也有了更加深刻的体会和分析
> 5.认识到了系统性能资源的重要性，对压力测试下整个集群的瓶颈有了一个整体概念


